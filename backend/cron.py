from db import collection, client as db_client
from pymongo.errors import ServerSelectionTimeoutError
import asyncio
from openai import AsyncOpenAI
from models.moderation import Moderation
from dotenv import load_dotenv

load_dotenv()

openai_client = AsyncOpenAI()


async def get_conversation(chat_name: str) -> tuple[list, list]:
    """
    Splits the conversation into texts between the user(child) and the suspect.
    """
    cursor = collection.find({"chat_name": chat_name}).sort("date_time", 1)
    user_texts = []
    suspect_texts = []

    user_flag = True
    curr_string = ""
    async for doc in cursor:
        # if doc.evaluated:
        #     continue

        if doc["sender"] == "me":
            if not user_flag:
                suspect_texts.append(curr_string)
                curr_string = ""
                user_flag = True
            curr_string += " " + doc["content"]

        else:
            if user_flag:
                user_texts.append(curr_string)
                curr_string = ""
                user_flag = False
            curr_string += " " + doc["content"]

        # await collection.update_one(
        #     filter={"_id": doc._id}, update={"$set": {"evaluated": True}}
        # )

    if user_flag:
        user_texts.append(curr_string)
    else:
        suspect_texts.append(curr_string)

    return user_texts, suspect_texts


async def generate_moderation_report(texts: list[str]) -> Moderation:
    """
    Performs text moderation and generates results.

    Args:
        texts: texts generated by a person
    """

    report = Moderation()

    response = await openai_client.moderations.create(
        model="omni-moderation-latest", input=texts
    )

    for result in response.results:
        report.flagged |= result.flagged
        report.sexual |= result.categories.sexual
        report.sexual_minors |= result.categories.sexual_minors
        report.harassment |= result.categories.harassment
        report.harassment_threatening |= result.categories.harassment_threatening
        report.hate |= result.categories.hate
        report.hate_threatening |= result.categories.hate_threatening
        report.illicit |= result.categories.illicit
        report.illicit_violent |= result.categories.illicit_violent
        report.self_harm |= result.categories.self_harm
        report.self_harm_intent |= result.categories.self_harm_intent
        report.self_harm_instructions |= result.categories.self_harm_instructions
        report.violence |= result.categories.violence
        report.violence_graphic |= result.categories.violence_graphic

    return report


async def main():
    try:
        await db_client.admin.command("ping")
        print("✔ MongoDB connection successful")
    except ServerSelectionTimeoutError as e:
        print({"error": "Could not connect to MongoDB", "details": str(e)})
        return

    chat_name = "Lexie HCI Group Project"

    user_texts, suspect_texts = await get_conversation(chat_name)

    user_report = await generate_moderation_report(user_texts)
    suspect_report = await generate_moderation_report(suspect_texts)

    if user_report.flagged or suspect_report.flagged:
        await collection.update_one(
            filter={"_id": "trigger_popup"}, update={"$set": {"value": True}}
        )

    if user_report.flagged:
        triggered_flags = [k for (k, v) in user_report.model_dump().items() if v]
        response = await openai_client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "You are a safety analyst tasked with generating behavioral reports"
                        "for children engaging in online chat platforms. Based on provided"
                        "moderation flags, write a concise, professional report that summarizes"
                        "the child’s behavior, highlights any concerns,and suggests possible"
                        "actions or follow-up steps. The tone should be objective, neutral, and"
                        "suitable for review by parents, guardians, or school officials."
                        "Await input: a list of moderation flags triggered."
                    ),
                },
                {
                    "role": "user",
                    "content": f"The user's conversations resulted in the activation of the following moderation flags: {','.join(triggered_flags)}",
                },
            ],
        )

        print(response.choices[0].message.content)

    if suspect_report.flagged:
        triggered_flags = [k for (k, v) in suspect_report.model_dump().items() if v]
        response = await openai_client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "You are a digital safety analyst assigned to monitor and report on potential"
                        "risks to children on online chat platforms. Your role is to identify and summarize"
                        "any behavior by the user that may indicate engagement in inappropriate,"
                        "harmful, or concerning interactions with the child. Based on provided moderation flags, write a"
                        "clear and professional report. The tone should remain neutral, factual, and suitable"
                        "for review by child safety officers, school administrators, or guardians. Do not include"
                        "any real names unless explicitly provided. Refer to the child as 'the child.' Await"
                        "input: a list of moderation flags triggered."
                    ),
                },
                {
                    "role": "user",
                    "content": f"The user's conversations resulted in the activation of the following moderation flags: {','.join(triggered_flags)}",
                },
            ],
        )

        print(response.choices[0].message.content)


if __name__ == "__main__":
    asyncio.run(main())
